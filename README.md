# GPTæ¨¡å‹è®­ç»ƒ - RT9700 ROCmç¯å¢ƒ

å®Œæ•´çš„GPTæ¨¡å‹è®­ç»ƒæ–¹æ¡ˆï¼Œæ”¯æŒå•GPUå’Œå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒã€‚

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ç¯å¢ƒå®‰è£…](#ç¯å¢ƒå®‰è£…)
- [é˜¶æ®µä¸€ï¼šå•GPUè®­ç»ƒ](#é˜¶æ®µä¸€å•gpuè®­ç»ƒ)
- [é˜¶æ®µäºŒï¼šå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ](#é˜¶æ®µäºŒå¤šgpuåˆ†å¸ƒå¼è®­ç»ƒ)
- [æµ‹è¯•æ¨¡å‹](#æµ‹è¯•æ¨¡å‹)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [é¡¹ç›®æ–‡ä»¶è¯´æ˜](#é¡¹ç›®æ–‡ä»¶è¯´æ˜)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ³ æ–¹å¼ä¸€ï¼šä½¿ç”¨Dockerï¼ˆæœ€ç®€å•ï¼Œå¼ºçƒˆæ¨èï¼‰

ä½¿ç”¨å®˜æ–¹ROCm PyTorch Dockeré•œåƒï¼Œé›¶é…ç½®å¼€å§‹è®­ç»ƒï¼

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd gpt_train

# 2. å¯åŠ¨Dockerå®¹å™¨ï¼ˆè‡ªåŠ¨æ‹‰å–é•œåƒå¹¶é…ç½®ç¯å¢ƒï¼‰
./docker_run.sh

# 3. å®¹å™¨å†…å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡ï¼‰
pip3 install -r requirements.txt

# 4. éªŒè¯GPU
python3 -c "import torch; print(torch.cuda.is_available())"

# 5. è¿è¡Œè®­ç»ƒ
python3 train_single_gpu.py --model_size tiny

# 6. æµ‹è¯•ç”Ÿæˆ
python3 test_generation.py
```

**Dockerä¼˜åŠ¿**ï¼š
- âœ… é¢„è£…PyTorch 2.8.0 + ROCm 7.1
- âœ… ç‰ˆæœ¬å®Œå…¨åŒ¹é…ï¼Œæ— å…¼å®¹æ€§é—®é¢˜
- âœ… å‡ åˆ†é’Ÿå³å¯å¼€å§‹è®­ç»ƒ
- âœ… ç¯å¢ƒéš”ç¦»ï¼Œä¸å½±å“ä¸»æœº

è¯¦ç»†æ–‡æ¡£ï¼š[DOCKER_SETUP.md](DOCKER_SETUP.md)

### ğŸ’» æ–¹å¼äºŒï¼šæœ¬åœ°ç¯å¢ƒï¼ˆä½¿ç”¨uvï¼‰

å¦‚æœæ‚¨éœ€è¦æ›´é«˜çš„çµæ´»æ€§æˆ–æ€§èƒ½å¾®è°ƒï¼š

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd gpt_train

# 2. å®‰è£…ç¯å¢ƒï¼ˆè‡ªåŠ¨å®‰è£…uvå¹¶é…ç½®ï¼‰
./setup_env.sh

# 3. è¿è¡Œè®­ç»ƒï¼ˆä½¿ç”¨é»˜è®¤tinyæ¨¡å‹ï¼Œ3è½®è®­ç»ƒï¼‰
chmod +x run_single_gpu.sh
./run_single_gpu.sh

# 4. æµ‹è¯•ç”Ÿæˆ
python3 test_generation.py

# æˆ–ä½¿ç”¨uvè¿è¡Œï¼ˆæ— éœ€æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼‰
uv run python test_generation.py
```

## ğŸ“¦ ç¯å¢ƒå®‰è£…

æœ¬é¡¹ç›®æ¨èä½¿ç”¨ **uv** æ¥ç®¡ç†Pythonç¯å¢ƒå’Œä¾èµ–ã€‚uvæ˜¯ä¸€ä¸ªæå¿«çš„PythonåŒ…ç®¡ç†å™¨ï¼Œæ¯”ä¼ ç»Ÿçš„pipå’Œvenvå¿«10-100å€ã€‚

### æ–¹æ³•ä¸€ï¼šè‡ªåŠ¨å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# è¿è¡Œsetupè„šæœ¬ï¼Œè‡ªåŠ¨å®‰è£…uvå¹¶é…ç½®ç¯å¢ƒ
./setup_env.sh
```

### æ–¹æ³•äºŒï¼šæ‰‹åŠ¨å®‰è£…

#### æ­¥éª¤1: å®‰è£…uv

```bash
# å®‰è£…uvï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# æ·»åŠ åˆ°PATHï¼ˆå¦‚æœéœ€è¦ï¼‰
export PATH="$HOME/.cargo/bin:$PATH"

# éªŒè¯å®‰è£…
uv --version
```

#### æ­¥éª¤2: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨uvåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆéå¸¸å¿«ï¼ï¼‰
uv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate
```

#### æ­¥éª¤3: å®‰è£…PyTorch (ROCmç‰ˆæœ¬)

```bash
# ä½¿ç”¨uvå®‰è£…PyTorch
# ROCm 6.1
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1

# ROCm 6.0
# uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.0
```

#### æ­¥éª¤4: å®‰è£…å…¶ä»–ä¾èµ–

```bash
# ä½¿ç”¨uvåŒæ­¥ä¾èµ–ï¼ˆä»pyproject.tomlï¼‰
uv pip install -r requirements.txt

# æˆ–ä½¿ç”¨pyproject.toml
uv pip install -e .
```

#### æ­¥éª¤5: éªŒè¯ç¯å¢ƒ

```bash
# æ£€æŸ¥PyTorchæ˜¯å¦èƒ½è¯†åˆ«GPU
python3 -c "import torch; print(f'GPUå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"

# æ£€æŸ¥ROCm
rocm-smi
```

### ä¼ ç»Ÿæ–¹å¼ï¼ˆvenv + pipï¼‰

å¦‚æœæ‚¨ä¸æƒ³ä½¿ç”¨uvï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ä¼ ç»Ÿçš„venvå’Œpipï¼š

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv gpt_train_env
source gpt_train_env/bin/activate

# å®‰è£…PyTorch
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1

# å®‰è£…ä¾èµ–
pip3 install -r requirements.txt
```

## ğŸ¯ é˜¶æ®µä¸€ï¼šå•GPUè®­ç»ƒ

### ä½¿ç”¨è„šæœ¬å¿«é€Ÿå¯åŠ¨

```bash
# åŸºç¡€è®­ç»ƒï¼ˆtinyæ¨¡å‹ï¼Œ3è½®ï¼‰
./run_single_gpu.sh

# è‡ªå®šä¹‰å‚æ•°
./run_single_gpu.sh <æ¨¡å‹å¤§å°> <è½®æ•°> <æ‰¹æ¬¡å¤§å°>

# ç¤ºä¾‹ï¼šè®­ç»ƒsmallæ¨¡å‹ï¼Œ5è½®ï¼Œæ‰¹æ¬¡å¤§å°16
./run_single_gpu.sh small 5 16
```

### æ‰‹åŠ¨å¯åŠ¨è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒ
python3 train_single_gpu.py \
    --model_size tiny \
    --epochs 3 \
    --batch_size 8 \
    --output_dir ./output_single \
    --model_save_dir ./gpt_model

# ä½¿ç”¨ä¸­æ–‡æ•°æ®é›†
python3 train_single_gpu.py \
    --model_size small \
    --epochs 5 \
    --batch_size 8 \
    --use_chinese \
    --output_dir ./output_single_chinese \
    --model_save_dir ./gpt_model_chinese
```

### æ¨¡å‹å¤§å°é€‰æ‹©

| æ¨¡å‹å¤§å° | å‚æ•°é‡ | æ˜¾å­˜éœ€æ±‚ | è®­ç»ƒæ—¶é•¿ | é€‚ç”¨åœºæ™¯ |
|---------|--------|---------|---------|---------|
| tiny    | ~50M   | <2GB    | å¿«é€Ÿ    | å¿«é€ŸéªŒè¯ |
| small   | ~117M  | ~3GB    | ä¸­ç­‰    | æ¨èå…¥é—¨ |
| medium  | ~345M  | ~8GB    | è¾ƒé•¿    | æ›´å¥½æ•ˆæœ |

### ç›‘æ§è®­ç»ƒ

```bash
# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
watch -n 1 rocm-smi

# ä½¿ç”¨TensorBoardæŸ¥çœ‹è®­ç»ƒæ›²çº¿
tensorboard --logdir=./output_single/logs
# ç„¶åè®¿é—® http://localhost:6006
```

## ğŸŒ é˜¶æ®µäºŒï¼šå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ

### å‰ç½®è¦æ±‚

1. **å¤šä¸ªGPUèŠ‚ç‚¹**ï¼ˆæ¯ä¸ªèŠ‚ç‚¹è‡³å°‘1å¼ GPUï¼‰
2. **ç½‘ç»œè¿é€š**ï¼ˆæ‰€æœ‰èŠ‚ç‚¹äº’ç›¸å¯è®¿é—®ï¼‰
3. **å…±äº«å­˜å‚¨**ï¼ˆæ¨èNFSï¼Œå‚è€ƒ `../nfs_setup.md`ï¼‰
4. **RCCLå·²å®‰è£…**ï¼ˆå‚è€ƒ `../rccl_install/`ï¼‰
5. **SSHå…å¯†ç™»å½•**

### å•æœºå¤šå¡è®­ç»ƒ

```bash
# ä½¿ç”¨è„šæœ¬ï¼ˆ4å¼ GPUï¼‰
./run_multi_gpu.sh small 5 16 4

# å‚æ•°è¯´æ˜:
# - small: æ¨¡å‹å¤§å°
# - 5: è®­ç»ƒè½®æ•°
# - 16: æ¯GPUæ‰¹æ¬¡å¤§å°
# - 4: GPUæ•°é‡
```

### å¤šæœºå¤šå¡è®­ç»ƒ

#### ä¸»èŠ‚ç‚¹ï¼ˆnode1ï¼ŒIP: 192.168.1.100ï¼‰

```bash
./run_multi_gpu.sh small 5 16 4 2 0 192.168.1.100 29500

# å‚æ•°è¯´æ˜:
# - small: æ¨¡å‹å¤§å°
# - 5: è®­ç»ƒè½®æ•°  
# - 16: æ¯GPUæ‰¹æ¬¡å¤§å°
# - 4: æ¯èŠ‚ç‚¹GPUæ•°
# - 2: æ€»èŠ‚ç‚¹æ•°
# - 0: å½“å‰èŠ‚ç‚¹rank (ä¸»èŠ‚ç‚¹ä¸º0)
# - 192.168.1.100: ä¸»èŠ‚ç‚¹IP
# - 29500: é€šä¿¡ç«¯å£
```

#### ä»èŠ‚ç‚¹ï¼ˆnode2ï¼Œåœ¨node2ä¸Šæ‰§è¡Œï¼‰

```bash
./run_multi_gpu.sh small 5 16 4 2 1 192.168.1.100 29500

# æ³¨æ„: node_rankæ”¹ä¸º1ï¼ˆä»èŠ‚ç‚¹ï¼‰
```

### æ‰‹åŠ¨å¯åŠ¨ï¼ˆæ›´å¤šæ§åˆ¶ï¼‰

```bash
# ä¸»èŠ‚ç‚¹
torchrun \
    --nproc_per_node=4 \
    --nnodes=2 \
    --node_rank=0 \
    --master_addr=192.168.1.100 \
    --master_port=29500 \
    train_multi_gpu.py \
    --model_size medium \
    --epochs 10 \
    --batch_size 16

# ä»èŠ‚ç‚¹
torchrun \
    --nproc_per_node=4 \
    --nnodes=2 \
    --node_rank=1 \
    --master_addr=192.168.1.100 \
    --master_port=29500 \
    train_multi_gpu.py \
    --model_size medium \
    --epochs 10 \
    --batch_size 16
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# è®¾ç½®ç½‘ç»œæ¥å£ï¼ˆæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
export NCCL_SOCKET_IFNAME=eth0

# å¦‚æœæ²¡æœ‰InfiniBand
export NCCL_IB_DISABLE=1

# è°ƒè¯•ä¿¡æ¯
export NCCL_DEBUG=INFO

# ä¸»èŠ‚ç‚¹ä¿¡æ¯
export MASTER_ADDR=192.168.1.100
export MASTER_PORT=29500
```

## ğŸ§ª æµ‹è¯•æ¨¡å‹

### åŸºç¡€æµ‹è¯•

```bash
# æµ‹è¯•å•GPUè®­ç»ƒçš„æ¨¡å‹
python3 test_generation.py --model_path ./gpt_model

# æµ‹è¯•åˆ†å¸ƒå¼è®­ç»ƒçš„æ¨¡å‹
python3 test_generation.py --model_path ./gpt_model_distributed
```

### è‡ªå®šä¹‰ç”Ÿæˆ

```bash
# è‡ªå®šä¹‰æç¤ºè¯å’Œå‚æ•°
python3 test_generation.py \
    --model_path ./gpt_model \
    --prompt "In a world where" \
    --max_length 150 \
    --num_return_sequences 5 \
    --temperature 0.9

# ä¸­æ–‡ç”Ÿæˆ
python3 test_generation.py \
    --model_path ./gpt_model_chinese \
    --prompt "ä»å‰æœ‰ä¸€ä¸ª" \
    --max_length 100
```

## â“ å¸¸è§é—®é¢˜

### 1. GPUä¸å¯ç”¨

```bash
# æ£€æŸ¥ROCm
rocm-smi

# æ£€æŸ¥PyTorch
python3 -c "import torch; print(torch.cuda.is_available())"

# å¦‚æœè¿”å›Falseï¼Œé‡æ–°å®‰è£…ROCmç‰ˆPyTorch
pip3 uninstall torch torchvision torchaudio
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1
```

### 2. æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰

```bash
# å‡å°æ‰¹æ¬¡å¤§å°
python3 train_single_gpu.py --batch_size 4

# æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
python3 train_single_gpu.py --model_size tiny
```

### 3. å¤šèŠ‚ç‚¹é€šä¿¡å¤±è´¥

```bash
# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
ping node2

# æ£€æŸ¥SSH
ssh node2 "hostname"

# æµ‹è¯•RCCL
cd ../rccl_install/rccl_multinode_test
./rccl_mpi_test

# æ£€æŸ¥é˜²ç«å¢™ç«¯å£
sudo ufw allow 29500
```

### 4. æ•°æ®é›†ä¸‹è½½å¤±è´¥

```bash
# ä½¿ç”¨é•œåƒæº
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†åä½¿ç”¨æœ¬åœ°è·¯å¾„
```

### 5. è®­ç»ƒé€Ÿåº¦æ…¢

- å‡å°`max_length`ï¼ˆåºåˆ—é•¿åº¦ï¼‰
- å¯ç”¨æ··åˆç²¾åº¦ï¼ˆå¦‚æœæ”¯æŒï¼‰: `--fp16`
- å¢åŠ `gradient_accumulation_steps`
- ä½¿ç”¨æ›´å¿«çš„æ•°æ®é›†åŠ è½½å™¨

## ğŸ“ é¡¹ç›®æ–‡ä»¶è¯´æ˜

```
gpt_train/
â”œâ”€â”€ TRAINING_PLAN.md          # è¯¦ç»†è®­ç»ƒè®¡åˆ’æ–‡æ¡£
â”œâ”€â”€ README.md                 # æœ¬æ–‡ä»¶ï¼ˆå¿«é€Ÿå¼€å§‹ï¼‰
â”œâ”€â”€ DOCKER_SETUP.md           # Dockerä½¿ç”¨æŒ‡å—ï¼ˆæ¨èé˜…è¯»ï¼‰
â”œâ”€â”€ SETUP_GUIDE.md            # æœ¬åœ°ç¯å¢ƒæ•…éšœæ’é™¤
â”‚
â”œâ”€â”€ pyproject.toml            # é¡¹ç›®é…ç½®ï¼ˆuvä½¿ç”¨ï¼‰
â”œâ”€â”€ requirements.txt          # Pythonä¾èµ–
â”œâ”€â”€ docker-compose.yml        # Docker Composeé…ç½®
â”œâ”€â”€ .gitignore               # Gitå¿½ç•¥è§„åˆ™
â”‚
â”œâ”€â”€ setup_env.sh              # æœ¬åœ°ç¯å¢ƒé…ç½®è„šæœ¬ï¼ˆuvï¼‰
â”œâ”€â”€ docker_run.sh             # Dockerå®¹å™¨å¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ train_single_gpu.py       # å•GPUè®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_multi_gpu.py        # å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_generation.py        # æ–‡æœ¬ç”Ÿæˆæµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ run_single_gpu.sh         # å•GPUå¯åŠ¨è„šæœ¬
â”œâ”€â”€ run_multi_gpu.sh          # å¤šGPUå¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ .venv/                    # è™šæ‹Ÿç¯å¢ƒï¼ˆæœ¬åœ°æ–¹å¼ï¼‰
â”œâ”€â”€ output_single/            # å•GPUè®­ç»ƒè¾“å‡ºï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”œâ”€â”€ output_distributed/       # å¤šGPUè®­ç»ƒè¾“å‡ºï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”œâ”€â”€ gpt_model/               # å•GPUæ¨¡å‹ä¿å­˜ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â””â”€â”€ gpt_model_distributed/   # å¤šGPUæ¨¡å‹ä¿å­˜ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

### æœ¬é¡¹ç›®æ–‡æ¡£
- ğŸ³ [Dockerä½¿ç”¨æŒ‡å—](DOCKER_SETUP.md) - **æ¨èæ–°æ‰‹é˜…è¯»**ï¼Œæœ€ç®€å•çš„å¼€å§‹æ–¹å¼
- ğŸ“– [è¯¦ç»†è®­ç»ƒè®¡åˆ’](TRAINING_PLAN.md) - å®Œæ•´çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ¡ˆ
- ğŸ”§ [ç¯å¢ƒæ•…éšœæ’é™¤](SETUP_GUIDE.md) - æœ¬åœ°ç¯å¢ƒé—®é¢˜è§£å†³æ–¹æ¡ˆ

### ç›¸å…³ç³»ç»Ÿé…ç½®
- [RCCLå®‰è£…å’Œæµ‹è¯•](../rccl_install/) - å¤šèŠ‚ç‚¹é€šä¿¡åº“
- [NFSé…ç½®](../nfs_setup.md) - å…±äº«å­˜å‚¨é…ç½®
- [ROCmå®‰è£…](../rocm_install/) - GPUé©±åŠ¨å®‰è£…

## ğŸ“ å­¦ä¹ èµ„æº

- [PyTorchåˆ†å¸ƒå¼è®­ç»ƒ](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [RCCLæ–‡æ¡£](https://github.com/ROCmSoftwarePlatform/rccl)
- [NanoGPTé¡¹ç›®](https://github.com/karpathy/nanoGPT)

## ğŸ’¡ ä½¿ç”¨uvçš„ä¼˜åŠ¿

1. **æå¿«çš„é€Ÿåº¦**ï¼šuvæ¯”pipå¿«10-100å€
2. **æ›´å¥½çš„ä¾èµ–è§£æ**ï¼šé¿å…ä¾èµ–å†²çª
3. **ç°ä»£åŒ–ä½“éªŒ**ï¼šæ›´å¥½çš„é”™è¯¯æç¤ºå’Œè¿›åº¦æ˜¾ç¤º
4. **å…¼å®¹pip**ï¼šå¯ä»¥æ— ç¼æ›¿æ¢pipå‘½ä»¤

### uvå¸¸ç”¨å‘½ä»¤

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv

# å®‰è£…åŒ…
uv pip install <package>

# å®‰è£…requirements.txt
uv pip install -r requirements.txt

# ä»pyproject.tomlå®‰è£…
uv pip install -e .

# åˆ—å‡ºå·²å®‰è£…çš„åŒ…
uv pip list

# è¿è¡Œè„šæœ¬ï¼ˆè‡ªåŠ¨ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼‰
uv run python script.py

# åŒæ­¥ä¾èµ–ï¼ˆç¡®ä¿ç¯å¢ƒä¸é…ç½®ä¸€è‡´ï¼‰
uv pip sync requirements.txt
```

## ğŸ”§ è¿›é˜¶ä¼˜åŒ–

### ä½¿ç”¨Wandbè·Ÿè¸ªå®éªŒ

```bash
# å®‰è£…wandb
pip3 install wandb

# ç™»å½•ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
wandb login

# åœ¨è®­ç»ƒè„šæœ¬ä¸­è‡ªåŠ¨å¯ç”¨
# è®¿é—® https://wandb.ai æŸ¥çœ‹å®éªŒ
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œå¦‚æœä¸­æ–­å¯ä»¥æ¢å¤ï¼š

```bash
# æ£€æŸ¥ç‚¹ä¼šä¿å­˜åœ¨ output_*/checkpoint-XXX/
ls output_single/

# è‡ªåŠ¨ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤ï¼ˆTrainerä¼šè‡ªåŠ¨å¤„ç†ï¼‰
```

## ğŸ“ ä¸‹ä¸€æ­¥

1. âœ… å®Œæˆç¯å¢ƒå®‰è£…
2. âœ… è¿è¡Œå•GPUè®­ç»ƒéªŒè¯ç¯å¢ƒ
3. âœ… æµ‹è¯•æ¨¡å‹ç”Ÿæˆæ•ˆæœ
4. âœ… é…ç½®å¤šèŠ‚ç‚¹ç½‘ç»œå’Œå­˜å‚¨
5. âœ… è¿è¡Œå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ
6. âœ… å¯¹æ¯”è®­ç»ƒæ•ˆç‡å’Œæ•ˆæœ

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** æŸ¥çœ‹ [TRAINING_PLAN.md](TRAINING_PLAN.md) è·å–æ›´è¯¦ç»†çš„è¯´æ˜ã€‚
