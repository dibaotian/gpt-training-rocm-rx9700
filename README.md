# GPTæ¨¡å‹è®­ç»ƒ - RT9700 ROCmç¯å¢ƒ

å®Œæ•´çš„GPTæ¨¡å‹è®­ç»ƒæ–¹æ¡ˆï¼Œæ”¯æŒå•GPUå’Œå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒã€‚

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ç¯å¢ƒå®‰è£…](#ç¯å¢ƒå®‰è£…)
- [é˜¶æ®µä¸€ï¼šå•GPUè®­ç»ƒ](#é˜¶æ®µä¸€å•gpuè®­ç»ƒ)
- [é˜¶æ®µäºŒï¼šå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ](#é˜¶æ®µäºŒå¤šgpuåˆ†å¸ƒå¼è®­ç»ƒ)
- [æµ‹è¯•æ¨¡å‹](#æµ‹è¯•æ¨¡å‹)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [é¡¹ç›®æ–‡ä»¶è¯´æ˜](#é¡¹ç›®æ–‡ä»¶è¯´æ˜)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ³ æ–¹å¼ä¸€ï¼šä½¿ç”¨Dockerï¼ˆæœ€ç®€å•ï¼Œå¼ºçƒˆæ¨èï¼‰

ä½¿ç”¨å®˜æ–¹ROCm PyTorch Dockeré•œåƒï¼Œé›¶é…ç½®å¼€å§‹è®­ç»ƒï¼

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd gpt_train

# 2. å¯åŠ¨Dockerå®¹å™¨ï¼ˆè‡ªåŠ¨æ‹‰å–é•œåƒå¹¶é…ç½®ç¯å¢ƒï¼‰
./docker_run.sh

# 3. å®¹å™¨å†…å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡ï¼‰
pip3 install -r requirements.txt

# 4. éªŒè¯GPU
python3 -c "import torch; print(torch.cuda.is_available())"

# 5. è¿è¡Œè®­ç»ƒ
python3 train_single_gpu.py --model_size tiny

# 6. æµ‹è¯•ç”Ÿæˆ
python3 test_generation.py
```

**Docker**ï¼š
- âœ… é¢„è£…PyTorch 2.8.0 + ROCm 7.1
è¯¦ç»†æ–‡æ¡£ï¼š[DOCKER_SETUP.md](DOCKER_SETUP.md)

### ğŸ’» æ–¹å¼äºŒï¼šæœ¬åœ°ç¯å¢ƒï¼ˆä½¿ç”¨uvï¼‰

å¦‚æœæ‚¨éœ€è¦æ›´é«˜çš„çµæ´»æ€§æˆ–æ€§èƒ½å¾®è°ƒï¼š

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd gpt_train

# 2. å®‰è£…ç¯å¢ƒï¼ˆè‡ªåŠ¨å®‰è£…uvå¹¶é…ç½®ï¼‰
./setup_env.sh

# 3. è¿è¡Œè®­ç»ƒï¼ˆä½¿ç”¨é»˜è®¤tinyæ¨¡å‹ï¼Œ3è½®è®­ç»ƒï¼‰
chmod +x run_single_gpu.sh
./run_single_gpu.sh

# 4. æµ‹è¯•ç”Ÿæˆ
python3 test_generation.py

# æˆ–ä½¿ç”¨uvè¿è¡Œï¼ˆæ— éœ€æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼‰
uv run python test_generation.py
```

## ğŸ“¦ ç¯å¢ƒå®‰è£…

æœ¬é¡¹ç›®æ¨èä½¿ç”¨ **uv** æ¥ç®¡ç†Pythonç¯å¢ƒå’Œä¾èµ–

### æ–¹æ³•ä¸€ï¼šè‡ªåŠ¨å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# è¿è¡Œsetupè„šæœ¬ï¼Œè‡ªåŠ¨å®‰è£…uvå¹¶é…ç½®ç¯å¢ƒ
./setup_env.sh
```

### æ–¹æ³•äºŒï¼šæ‰‹åŠ¨å®‰è£…

#### æ­¥éª¤1: å®‰è£…uv

```bash
# å®‰è£…uvï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# æ·»åŠ åˆ°PATHï¼ˆå¦‚æœéœ€è¦ï¼‰
export PATH="$HOME/.local/bin:$PATH"

# éªŒè¯å®‰è£…
uv --version
```

#### æ­¥éª¤2: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨uvåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆéå¸¸å¿«ï¼ï¼‰
uv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate
```

#### æ­¥éª¤3: å®‰è£…PyTorch (ROCmç‰ˆæœ¬)

```bash
# ä½¿ç”¨uvå®‰è£…PyTorch(ç›®å‰æ‰¾ä¸åˆ°rocm7.1 åªèƒ½é™çº§åˆ°6.3)
# ROCm 6.3
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3

or 

pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/rocm6.3

```

#### æ­¥éª¤4: å®‰è£…å…¶ä»–ä¾èµ–

```bash
# ä½¿ç”¨uvåŒæ­¥ä¾èµ–ï¼ˆä»pyproject.tomlï¼‰
uv pip install -r requirements.txt

# æˆ–ä½¿ç”¨pyproject.toml
uv pip install -e .
```

#### æ­¥éª¤5: éªŒè¯ç¯å¢ƒ

```bash
# æ£€æŸ¥PyTorchæ˜¯å¦èƒ½è¯†åˆ«GPU
python3 -c "import torch; print(f'GPUå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"

# æ£€æŸ¥ROCm
rocm-smi
```

## ğŸ¯ é˜¶æ®µä¸€ï¼šå•GPUè®­ç»ƒ

### ä½¿ç”¨è„šæœ¬å¿«é€Ÿå¯åŠ¨

```bash
# åŸºç¡€è®­ç»ƒï¼ˆtinyæ¨¡å‹ï¼Œ3è½®ï¼‰
./run_single_gpu.sh

# è‡ªå®šä¹‰å‚æ•°
./run_single_gpu.sh <æ¨¡å‹å¤§å°> <è½®æ•°> <æ‰¹æ¬¡å¤§å°>

# ç¤ºä¾‹ï¼šè®­ç»ƒsmallæ¨¡å‹ï¼Œ5è½®ï¼Œæ‰¹æ¬¡å¤§å°16
./run_single_gpu.sh small 5 16
```

### æ‰‹åŠ¨å¯åŠ¨è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒ
python3 train_single_gpu.py \
    --model_size tiny \
    --epochs 3 \
    --batch_size 8 \
    --output_dir ./output_single \
    --model_save_dir ./gpt_model

# ä½¿ç”¨ä¸­æ–‡æ•°æ®é›†
python3 train_single_gpu.py \
    --model_size small \
    --epochs 5 \
    --batch_size 8 \
    --use_chinese \
    --output_dir ./output_single_chinese \
    --model_save_dir ./gpt_model_chinese
```

### æ¨¡å‹å¤§å°é€‰æ‹©

| æ¨¡å‹å¤§å° | å‚æ•°é‡ | æ˜¾å­˜éœ€æ±‚ |
|---------|--------|---------|
| tiny    | ~50M   | <2GB    | 
| small   | ~117M  | ~3GB    | 
| medium  | ~345M  | ~8GB    | 

### ç›‘æ§è®­ç»ƒ

```bash
# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
watch -n 1 rocm-smi

# ä½¿ç”¨TensorBoardæŸ¥çœ‹è®­ç»ƒæ›²çº¿
tensorboard --logdir=./output_single/logs
# ç„¶åè®¿é—® http://localhost:6006
```

## ğŸŒ é˜¶æ®µäºŒï¼šå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ

### å‰ç½®è¦æ±‚

1. **å¤šä¸ªGPUèŠ‚ç‚¹**ï¼ˆæ¯ä¸ªèŠ‚ç‚¹è‡³å°‘1å¼ GPUï¼‰
2. **ç½‘ç»œè¿é€š**ï¼ˆæ‰€æœ‰èŠ‚ç‚¹äº’ç›¸å¯è®¿é—®ï¼‰
3. **å…±äº«å­˜å‚¨**ï¼ˆæ¨èNFSï¼Œå‚è€ƒ `../nfs_setup.md`ï¼‰
4. **RCCLå·²å®‰è£…**ï¼ˆå‚è€ƒ `../rccl_install/`ï¼‰
5. **SSHå…å¯†ç™»å½•**

### å•æœºå¤šå¡è®­ç»ƒ

```bash
# ä½¿ç”¨è„šæœ¬ï¼ˆ4å¼ GPUï¼‰
./run_multi_gpu.sh small 5 16 4

# å‚æ•°è¯´æ˜:
# - small: æ¨¡å‹å¤§å°
# - 5: è®­ç»ƒè½®æ•°
# - 16: æ¯GPUæ‰¹æ¬¡å¤§å°
# - 4: GPUæ•°é‡
```

### å¤šæœºå¤šå¡è®­ç»ƒ

#### ä¸»èŠ‚ç‚¹ï¼ˆnode1ï¼ŒIP: 192.168.1.100ï¼‰

```bash
./run_multi_gpu.sh small 5 16 4 2 0 192.168.1.100 29500

# å‚æ•°è¯´æ˜:
# - small: æ¨¡å‹å¤§å°
# - 5: è®­ç»ƒè½®æ•°  
# - 16: æ¯GPUæ‰¹æ¬¡å¤§å°
# - 4: æ¯èŠ‚ç‚¹GPUæ•°
# - 2: æ€»èŠ‚ç‚¹æ•°
# - 0: å½“å‰èŠ‚ç‚¹rank (ä¸»èŠ‚ç‚¹ä¸º0)
# - 192.168.1.100: ä¸»èŠ‚ç‚¹IP
# - 29500: é€šä¿¡ç«¯å£
```

#### ä»èŠ‚ç‚¹ï¼ˆnode2ï¼Œåœ¨node2ä¸Šæ‰§è¡Œï¼‰

```bash
./run_multi_gpu.sh small 5 16 4 2 1 192.168.1.100 29500

# æ³¨æ„: node_rankæ”¹ä¸º1ï¼ˆä»èŠ‚ç‚¹ï¼‰
```

### æ‰‹åŠ¨å¯åŠ¨ï¼ˆæ›´å¤šæ§åˆ¶ï¼‰

```bash
# ä¸»èŠ‚ç‚¹
torchrun \
    --nproc_per_node=4 \
    --nnodes=2 \
    --node_rank=0 \
    --master_addr=192.168.1.100 \
    --master_port=29500 \
    train_multi_gpu.py \
    --model_size medium \
    --epochs 10 \
    --batch_size 16

# ä»èŠ‚ç‚¹
torchrun \
    --nproc_per_node=4 \
    --nnodes=2 \
    --node_rank=1 \
    --master_addr=192.168.1.100 \
    --master_port=29500 \
    train_multi_gpu.py \
    --model_size medium \
    --epochs 10 \
    --batch_size 16
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# è®¾ç½®ç½‘ç»œæ¥å£ï¼ˆæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
export NCCL_SOCKET_IFNAME=eth0

# å¦‚æœæ²¡æœ‰InfiniBand
export NCCL_IB_DISABLE=1

# è°ƒè¯•ä¿¡æ¯
export NCCL_DEBUG=INFO

# ä¸»èŠ‚ç‚¹ä¿¡æ¯
export MASTER_ADDR=192.168.1.100
export MASTER_PORT=29500
```

## ğŸ“Š ä½¿ç”¨ TensorBoard ç›‘æ§è®­ç»ƒ

### ä»€ä¹ˆæ˜¯ TensorBoardï¼Ÿ

TensorBoard æ˜¯ä¸€ä¸ªå¯è§†åŒ–å·¥å…·ï¼Œå¯ä»¥å®æ—¶æŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡ï¼ˆæŸå¤±ã€å­¦ä¹ ç‡ç­‰ï¼‰ï¼Œå¸®åŠ©æ‚¨ï¼š
- å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦
- åˆ†æè®­ç»ƒæ•ˆæœ
- å¯¹æ¯”ä¸åŒå®éªŒ
- è°ƒè¯•è®­ç»ƒé—®é¢˜

### å¯åŠ¨ TensorBoard

è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨å°†æ—¥å¿—ä¿å­˜åˆ°è¾“å‡ºç›®å½•çš„ `logs` å­ç›®å½•ä¸­ã€‚

#### æ–¹æ³•1ï¼šè®­ç»ƒæ—¶å¯åŠ¨ï¼ˆæ¨èï¼‰

```bash
# åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œå¦å¼€ä¸€ä¸ªç»ˆç«¯å¯åŠ¨ TensorBoard
tensorboard --logdir=./output_single/logs --port=6006

# æˆ–æŒ‡å®šå¤šä¸ªå®éªŒç›®å½•
tensorboard --logdir_spec=single:./output_single/logs,multi:./output_distributed/logs
```

#### æ–¹æ³•2ï¼šè®­ç»ƒåæŸ¥çœ‹

```bash
# æŸ¥çœ‹å•GPUè®­ç»ƒç»“æœ
tensorboard --logdir=./output_single/logs

# æŸ¥çœ‹å¤šGPUè®­ç»ƒç»“æœ  
tensorboard --logdir=./output_distributed/logs

# æŸ¥çœ‹ä¸­æ–‡è®­ç»ƒç»“æœ
tensorboard --logdir=./output_single_chinese/logs
```

### è®¿é—® TensorBoard

å¯åŠ¨åï¼Œåœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š
```
http://localhost:6006
```

å¦‚æœæ˜¯è¿œç¨‹æœåŠ¡å™¨ï¼Œéœ€è¦ç«¯å£è½¬å‘ï¼š
```bash
# åœ¨æœ¬åœ°æœºå™¨ä¸Šæ‰§è¡Œ
ssh -L 6006:localhost:6006 user@server_ip
```

### TensorBoard ç•Œé¢è¯´æ˜

#### 1. **SCALARS** æ ‡ç­¾é¡µï¼ˆæœ€å¸¸ç”¨ï¼‰
- `train/loss` - è®­ç»ƒæŸå¤±æ›²çº¿
- `train/learning_rate` - å­¦ä¹ ç‡å˜åŒ–
- `train/epoch` - å½“å‰è®­ç»ƒè½®æ•°
- `train/global_step` - è®­ç»ƒæ­¥æ•°

#### 2. **æŸ¥çœ‹è®­ç»ƒæŒ‡æ ‡**
```
- æŸå¤±ä¸‹é™è¶‹åŠ¿ï¼šåº”è¯¥æŒç»­ä¸‹é™å¹¶è¶‹äºç¨³å®š
- å­¦ä¹ ç‡ï¼šæŸ¥çœ‹å­¦ä¹ ç‡è°ƒåº¦æ˜¯å¦æ­£å¸¸
- è®­ç»ƒé€Ÿåº¦ï¼šæ¯æ­¥è€—æ—¶ï¼ˆsamples/secï¼‰
```

#### 3. **å¯¹æ¯”å¤šä¸ªå®éªŒ**
```bash
# åŒæ—¶æŸ¥çœ‹å¤šä¸ªè®­ç»ƒè¿è¡Œ
tensorboard --logdir=./output_single --port=6006

# ç›®å½•ç»“æ„ç¤ºä¾‹ï¼š
# output_single/
#   â”œâ”€â”€ run1_tiny_3epochs/logs/
#   â”œâ”€â”€ run2_small_5epochs/logs/
#   â””â”€â”€ run3_medium_10epochs/logs/
```

### è®­ç»ƒæ—¥å¿—ä½ç½®

é»˜è®¤æ—¥å¿—ä¿å­˜è·¯å¾„ï¼š
```
å•GPUè®­ç»ƒï¼š
  ./output_single/logs/
  ./output_single_optimized/logs/

å¤šGPUè®­ç»ƒï¼š
  ./output_distributed/logs/
  
ä¸­æ–‡è®­ç»ƒï¼š
  ./output_single_chinese/logs/
```

### TensorBoard é«˜çº§ç”¨æ³•

#### åå°è¿è¡Œ

```bash
# åå°å¯åŠ¨ TensorBoard
nohup tensorboard --logdir=./output_single/logs --port=6006 > tensorboard.log 2>&1 &

# æŸ¥çœ‹æ—¥å¿—
tail -f tensorboard.log

# åœæ­¢
pkill -f tensorboard
```

#### æŒ‡å®šä¸»æœºå’Œç«¯å£

```bash
# å…è®¸å¤–éƒ¨è®¿é—®
tensorboard --logdir=./output_single/logs --host=0.0.0.0 --port=6006

# ä½¿ç”¨ä¸åŒç«¯å£
tensorboard --logdir=./output_single/logs --port=6007
```

#### å¤šå®éªŒå¯¹æ¯”

```bash
# æ–¹å¼1ï¼šå¤šä¸ªç›®å½•
tensorboard --logdir_spec=\
tiny:./output_tiny/logs,\
small:./output_small/logs,\
medium:./output_medium/logs

# æ–¹å¼2ï¼šçˆ¶ç›®å½•ï¼ˆè‡ªåŠ¨è¯†åˆ«å­ç›®å½•ï¼‰
tensorboard --logdir=./all_experiments/
```

### ç¤ºä¾‹ï¼šå®Œæ•´è®­ç»ƒ+ç›‘æ§æµç¨‹

```bash
# ç»ˆç«¯1ï¼šå¯åŠ¨ TensorBoard
tensorboard --logdir=./output_single/logs --port=6006

# ç»ˆç«¯2ï¼šå¼€å§‹è®­ç»ƒ
python3 train_single_gpu.py --model_size small --epochs 5

# ç»ˆç«¯3ï¼šç›‘æ§GPU
watch -n 1 rocm-smi

# æµè§ˆå™¨ï¼šè®¿é—® http://localhost:6006 æŸ¥çœ‹è®­ç»ƒæ›²çº¿
```

### å¯¼å‡ºè®­ç»ƒæ›²çº¿

```bash
# TensorBoard æ”¯æŒå¯¼å‡ºæ•°æ®ä¸º CSV
# åœ¨ TensorBoard ç•Œé¢ç‚¹å‡»å·¦ä¸‹è§’çš„ä¸‹è½½æŒ‰é’®

# æˆ–ä½¿ç”¨ Python è¯»å–äº‹ä»¶æ–‡ä»¶
python3 -c "
from tensorboard.backend.event_processing import event_accumulator
ea = event_accumulator.EventAccumulator('./output_single/logs/events.out.tfevents.*')
ea.Reload()
print(ea.Tags())
"
```

---

## ğŸ§ª æµ‹è¯•æ¨¡å‹

### åŸºç¡€æµ‹è¯•

```bash
# æµ‹è¯•å•GPUè®­ç»ƒçš„æ¨¡å‹
python3 test_generation.py --model_path ./gpt_model

# æµ‹è¯•åˆ†å¸ƒå¼è®­ç»ƒçš„æ¨¡å‹
python3 test_generation.py --model_path ./gpt_model_distributed
```

### è‡ªå®šä¹‰ç”Ÿæˆ

```bash
# è‡ªå®šä¹‰æç¤ºè¯å’Œå‚æ•°
python3 test_generation.py \
    --model_path ./gpt_model \
    --prompt "In a world where" \
    --max_length 150 \
    --num_return_sequences 5 \
    --temperature 0.9

# ä¸­æ–‡ç”Ÿæˆ
python3 test_generation.py \
    --model_path ./gpt_model_chinese \
    --prompt "ä»å‰æœ‰ä¸€ä¸ª" \
    --max_length 100
```

## â“ å¸¸è§é—®é¢˜

### 1. GPUä¸å¯ç”¨

```bash
# æ£€æŸ¥ROCm
rocm-smi

# æ£€æŸ¥PyTorch
python3 -c "import torch; print(torch.cuda.is_available())"

# å¦‚æœè¿”å›Falseï¼Œé‡æ–°å®‰è£…ROCmç‰ˆPyTorch
pip3 uninstall torch torchvision torchaudio
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1
```

### 2. æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰

```bash
# å‡å°æ‰¹æ¬¡å¤§å°
python3 train_single_gpu.py --batch_size 4

# æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
python3 train_single_gpu.py --model_size tiny
```

### 3. å¤šèŠ‚ç‚¹é€šä¿¡å¤±è´¥

```bash
# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
ping node2

# æ£€æŸ¥SSH
ssh node2 "hostname"

# æµ‹è¯•RCCL
cd ../rccl_install/rccl_multinode_test
./rccl_mpi_test

# æ£€æŸ¥é˜²ç«å¢™ç«¯å£
sudo ufw allow 29500
```

### 4. æ•°æ®é›†ä¸‹è½½å¤±è´¥

```bash
# ä½¿ç”¨é•œåƒæº
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†åä½¿ç”¨æœ¬åœ°è·¯å¾„
```

### 5. è®­ç»ƒé€Ÿåº¦æ…¢

- å‡å°`max_length`ï¼ˆåºåˆ—é•¿åº¦ï¼‰
- å¯ç”¨æ··åˆç²¾åº¦ï¼ˆå¦‚æœæ”¯æŒï¼‰: `--bf16`
- å¢åŠ `gradient_accumulation_steps`
- ä½¿ç”¨æ›´å¿«çš„æ•°æ®é›†åŠ è½½å™¨

## ğŸ“ é¡¹ç›®æ–‡ä»¶è¯´æ˜

```
gpt_train/
â”œâ”€â”€ TRAINING_PLAN.md          # è¯¦ç»†è®­ç»ƒè®¡åˆ’æ–‡æ¡£
â”œâ”€â”€ README.md                 # æœ¬æ–‡ä»¶ï¼ˆå¿«é€Ÿå¼€å§‹ï¼‰
â”œâ”€â”€ DOCKER_SETUP.md           # Dockerä½¿ç”¨æŒ‡å—ï¼ˆæ¨èé˜…è¯»ï¼‰
â”œâ”€â”€ SETUP_GUIDE.md            # æœ¬åœ°ç¯å¢ƒæ•…éšœæ’é™¤
â”‚
â”œâ”€â”€ pyproject.toml            # é¡¹ç›®é…ç½®ï¼ˆuvä½¿ç”¨ï¼‰
â”œâ”€â”€ requirements.txt          # Pythonä¾èµ–
â”œâ”€â”€ docker-compose.yml        # Docker Composeé…ç½®
â”œâ”€â”€ .gitignore               # Gitå¿½ç•¥è§„åˆ™
â”‚
â”œâ”€â”€ setup_env.sh              # æœ¬åœ°ç¯å¢ƒé…ç½®è„šæœ¬ï¼ˆuvï¼‰
â”œâ”€â”€ docker_run.sh             # Dockerå®¹å™¨å¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ train_single_gpu.py       # å•GPUè®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_multi_gpu.py        # å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_generation.py        # æ–‡æœ¬ç”Ÿæˆæµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ run_single_gpu.sh         # å•GPUå¯åŠ¨è„šæœ¬
â”œâ”€â”€ run_multi_gpu.sh          # å¤šGPUå¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ .venv/                    # è™šæ‹Ÿç¯å¢ƒï¼ˆæœ¬åœ°æ–¹å¼ï¼‰
â”œâ”€â”€ output_single/            # å•GPUè®­ç»ƒè¾“å‡ºï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”œâ”€â”€ output_distributed/       # å¤šGPUè®­ç»ƒè¾“å‡ºï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”œâ”€â”€ gpt_model/               # å•GPUæ¨¡å‹ä¿å­˜ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â””â”€â”€ gpt_model_distributed/   # å¤šGPUæ¨¡å‹ä¿å­˜ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

### æœ¬é¡¹ç›®æ–‡æ¡£
- ğŸ³ [Dockerä½¿ç”¨æŒ‡å—](DOCKER_SETUP.md) - **æ¨èæ–°æ‰‹é˜…è¯»**ï¼Œæœ€ç®€å•çš„å¼€å§‹æ–¹å¼
- ğŸ“– [è¯¦ç»†è®­ç»ƒè®¡åˆ’](TRAINING_PLAN.md) - å®Œæ•´çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ¡ˆ
- ğŸ”§ [ç¯å¢ƒæ•…éšœæ’é™¤](SETUP_GUIDE.md) - æœ¬åœ°ç¯å¢ƒé—®é¢˜è§£å†³æ–¹æ¡ˆ

### ç›¸å…³ç³»ç»Ÿé…ç½®
- [RCCLå®‰è£…å’Œæµ‹è¯•](../rccl_install/) - å¤šèŠ‚ç‚¹é€šä¿¡åº“
- [NFSé…ç½®](../nfs_setup.md) - å…±äº«å­˜å‚¨é…ç½®
- [ROCmå®‰è£…](../rocm_install/) - GPUé©±åŠ¨å®‰è£…

## ğŸ“ å­¦ä¹ èµ„æº

- [PyTorchåˆ†å¸ƒå¼è®­ç»ƒ](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [RCCLæ–‡æ¡£](https://github.com/ROCmSoftwarePlatform/rccl)
- [NanoGPTé¡¹ç›®](https://github.com/karpathy/nanoGPT)

### ä½¿ç”¨Wandbè·Ÿè¸ªå®éªŒ

```bash
# å®‰è£…wandb
pip3 install wandb

# ç™»å½•ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
wandb login

# åœ¨è®­ç»ƒè„šæœ¬ä¸­è‡ªåŠ¨å¯ç”¨
# è®¿é—® https://wandb.ai æŸ¥çœ‹å®éªŒ
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œå¦‚æœä¸­æ–­å¯ä»¥æ¢å¤ï¼š

```bash
# æ£€æŸ¥ç‚¹ä¼šä¿å­˜åœ¨ output_*/checkpoint-XXX/
ls output_single/

# è‡ªåŠ¨ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤ï¼ˆTrainerä¼šè‡ªåŠ¨å¤„ç†ï¼‰
```

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** æŸ¥çœ‹ [TRAINING_PLAN.md](TRAINING_PLAN.md) è·å–æ›´è¯¦ç»†çš„è¯´æ˜ã€‚
