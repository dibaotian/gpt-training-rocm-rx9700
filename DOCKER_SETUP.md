# ä½¿ç”¨Dockerè®­ç»ƒGPTæ¨¡å‹ - æœ€ç®€å•çš„æ–¹å¼

## ğŸ³ ä¸ºä»€ä¹ˆä½¿ç”¨Dockerï¼Ÿ

ä½¿ç”¨ROCmå®˜æ–¹Dockeré•œåƒçš„ä¼˜åŠ¿ï¼š
- âœ… **é›¶é…ç½®**ï¼šé¢„è£…PyTorch 2.8.0 + ROCm 7.1ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ç¯å¢ƒ
- âœ… **ç‰ˆæœ¬åŒ¹é…**ï¼šå®˜æ–¹ä¿è¯PyTorchä¸ROCmç‰ˆæœ¬å®Œå…¨å…¼å®¹
- âœ… **ç¯å¢ƒéš”ç¦»**ï¼šä¸å½±å“ä¸»æœºç³»ç»Ÿ
- âœ… **å¿«é€Ÿå¯åŠ¨**ï¼šå‡ åˆ†é’Ÿå³å¯å¼€å§‹è®­ç»ƒ
- âœ… **å¯ç§»æ¤**ï¼šåœ¨ä¸åŒæœºå™¨ä¸Šé‡ç°ç›¸åŒç¯å¢ƒ

## âš¡ è¶…å¿«é€Ÿå¼€å§‹ï¼ˆ3æ­¥ï¼‰

```bash
# 1. å®‰è£…Dockerï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
./install_docker.sh

# 2. é‡æ–°ç™»å½•ç³»ç»Ÿï¼ˆä½¿dockerç»„æƒé™ç”Ÿæ•ˆï¼‰

# 3. å¯åŠ¨è®­ç»ƒ
./docker_run.sh
```

## ğŸ“¦ å¯ç”¨çš„å®˜æ–¹é•œåƒ

### ROCm 7.1 + PyTorch 2.8.0
```bash
rocm/pytorch:rocm7.1_ubuntu22.04_py3.10_pytorch_release_2.8.0
```

æŸ¥çœ‹æ‰€æœ‰é•œåƒï¼šhttps://hub.docker.com/r/rocm/pytorch/tags

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆDockeræ–¹å¼ï¼‰

### å‰ç½®æ­¥éª¤ï¼šå®‰è£…Docker

#### è‡ªåŠ¨å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# è¿è¡Œå®‰è£…è„šæœ¬ï¼ˆè‡ªåŠ¨å®Œæˆæ‰€æœ‰é…ç½®ï¼‰
./install_docker.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. âœ… å®‰è£…Docker
2. âœ… å¯åŠ¨DockeræœåŠ¡
3. âœ… æ·»åŠ ç”¨æˆ·åˆ°dockerç»„
4. âœ… æµ‹è¯•GPUè®¿é—®

**âš ï¸ é‡è¦**ï¼šå®‰è£…å®Œæˆåå¿…é¡»**é‡æ–°ç™»å½•ç³»ç»Ÿ**ï¼Œdockerç»„æƒé™æ‰ä¼šç”Ÿæ•ˆï¼

#### æ‰‹åŠ¨å®‰è£…

å¦‚æœè‡ªåŠ¨è„šæœ¬å¤±è´¥ï¼Œå¯ä»¥æ‰‹åŠ¨å®‰è£…ï¼š

```bash
# 1. å®‰è£…Docker
sudo apt-get update
sudo apt-get install -y docker.io

# 2. å¯åŠ¨DockeræœåŠ¡
sudo systemctl start docker
sudo systemctl enable docker

# 3. æ·»åŠ ç”¨æˆ·åˆ°dockerç»„ï¼ˆé¿å…æ¯æ¬¡sudoï¼‰
sudo usermod -a -G docker $USER

# 4. é‡æ–°ç™»å½•ç³»ç»Ÿä½¿æ›´æ”¹ç”Ÿæ•ˆ
# æˆ–ä¸´æ—¶åˆ‡æ¢ç»„ï¼šnewgrp docker
```

#### éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥Docker
docker --version
docker ps

# æ£€æŸ¥GPUè®¿é—®
docker run -it --rm --device=/dev/kfd --device=/dev/dri rocm/rocm-terminal rocm-smi
```

#### å¸¸è§é—®é¢˜

**é—®é¢˜ï¼špermission denied while trying to connect to Docker daemon socket**

```bash
# åŸå› ï¼šç”¨æˆ·ä¸åœ¨dockerç»„æˆ–æœªé‡æ–°ç™»å½•
# è§£å†³æ–¹æ¡ˆ1ï¼šé‡æ–°ç™»å½•ç³»ç»Ÿ
# è§£å†³æ–¹æ¡ˆ2ï¼šä¸´æ—¶åˆ‡æ¢ç»„
newgrp docker

# è§£å†³æ–¹æ¡ˆ3ï¼šæ£€æŸ¥ç”¨æˆ·ç»„
groups
# åº”è¯¥çœ‹åˆ° docker

# å¦‚æœæ²¡æœ‰dockerç»„ï¼Œæ‰‹åŠ¨æ·»åŠ 
sudo usermod -a -G docker $USER
# ç„¶åé‡æ–°ç™»å½•
```

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨æä¾›çš„è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd gpt_train

# 1. å¯åŠ¨Dockerå®¹å™¨å¹¶è¿›å…¥
./docker_run.sh

# å®¹å™¨å†…å·²ç»é¢„è£…å¥½æ‰€æœ‰ç¯å¢ƒï¼Œç›´æ¥è®­ç»ƒ
python3 train_single_gpu.py --model_size tiny

# æµ‹è¯•ç”Ÿæˆ
python3 test_generation.py
```

### æ–¹æ³•äºŒï¼šæ‰‹åŠ¨å¯åŠ¨Docker

```bash
cd gpt_train

# å¯åŠ¨å®¹å™¨
docker run -it --rm \
  --device=/dev/kfd \
  --device=/dev/dri \
  --group-add video \
  --group-add render \
  --cap-add=SYS_PTRACE \
  --security-opt seccomp=unconfined \
  --ipc=host \
  --shm-size 8G \
  -v $(pwd):/workspace \
  -w /workspace \
  rocm/pytorch:rocm7.1_ubuntu22.04_py3.10_pytorch_release_2.8.0 \
  /bin/bash

# å®¹å™¨å†…å®‰è£…é¢å¤–ä¾èµ–
pip3 install transformers datasets tokenizers tensorboard wandb

# è®­ç»ƒ
python3 train_single_gpu.py --model_size tiny
```

---

## ğŸ”§ Dockeré…ç½®æ–‡ä»¶

### docker-compose.yml

```yaml
version: '3.8'

services:
  gpt-train:
    image: rocm/pytorch:rocm7.1_ubuntu22.04_py3.10_pytorch_release_2.8.0
    container_name: gpt-train-rocm
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - video
      - render
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    ipc: host
    shm_size: 8G
    volumes:
      - ./:/workspace
      - ./data:/data
      - ./models:/models
    working_dir: /workspace
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.0.0
      - PYTORCH_ROCM_ARCH=gfx1100
    command: /bin/bash
    stdin_open: true
    tty: true
```

ä½¿ç”¨ï¼š
```bash
# å¯åŠ¨å®¹å™¨
docker-compose up -d

# è¿›å…¥å®¹å™¨
docker-compose exec gpt-train bash

# åœæ­¢å®¹å™¨
docker-compose down
```

---

## ğŸ“‹ å®Œæ•´å·¥ä½œæµç¨‹

### å•GPUè®­ç»ƒï¼ˆDockerï¼‰

```bash
# 1. å¯åŠ¨å®¹å™¨
./docker_run.sh

# 2. å®¹å™¨å†…å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡ï¼‰
pip3 install -r requirements.txt

# 3. éªŒè¯GPU
python3 -c "import torch; print(torch.cuda.is_available())"
rocm-smi

# 4. è¿è¡Œè®­ç»ƒ
python3 train_single_gpu.py \
    --model_size small \
    --epochs 5 \
    --batch_size 16

# 5. æµ‹è¯•æ¨¡å‹
python3 test_generation.py --model_path ./gpt_model

# 6. é€€å‡ºå®¹å™¨
exit
```

### å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒï¼ˆDockerï¼‰

#### å•æœºå¤šå¡

```bash
# å¯åŠ¨å®¹å™¨ï¼ˆæ‰€æœ‰GPUï¼‰
docker run -it --rm \
  --device=/dev/kfd \
  --device=/dev/dri \
  --group-add video \
  --group-add render \
  --cap-add=SYS_PTRACE \
  --security-opt seccomp=unconfined \
  --ipc=host \
  --shm-size 16G \
  -v $(pwd):/workspace \
  -w /workspace \
  rocm/pytorch:rocm7.1_ubuntu22.04_py3.10_pytorch_release_2.8.0 \
  bash -c "pip3 install -r requirements.txt && torchrun --nproc_per_node=4 train_multi_gpu.py --model_size medium"
```

#### å¤šæœºå¤šå¡

æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œï¼š

**ä¸»èŠ‚ç‚¹ï¼ˆnode1ï¼‰ï¼š**
```bash
docker run -it --rm \
  --network=host \
  --device=/dev/kfd \
  --device=/dev/dri \
  --group-add video \
  --group-add render \
  --cap-add=SYS_PTRACE \
  --security-opt seccomp=unconfined \
  --ipc=host \
  --shm-size 16G \
  -v /path/to/shared/storage:/workspace \
  -w /workspace \
  -e MASTER_ADDR=192.168.1.100 \
  -e MASTER_PORT=29500 \
  rocm/pytorch:rocm7.1_ubuntu22.04_py3.10_pytorch_release_2.8.0 \
  bash -c "pip3 install -r requirements.txt && torchrun --nproc_per_node=4 --nnodes=2 --node_rank=0 --master_addr=192.168.1.100 --master_port=29500 train_multi_gpu.py"
```

**ä»èŠ‚ç‚¹ï¼ˆnode2ï¼‰ï¼š**
```bash
# åŒä¸Šï¼Œåªéœ€ä¿®æ”¹ --node_rank=1
```

---

## ğŸ’¡ Docker vs æœ¬åœ°ç¯å¢ƒ

| ç‰¹æ€§ | Docker | æœ¬åœ°ç¯å¢ƒ |
|------|--------|---------|
| é…ç½®éš¾åº¦ | â­ ç®€å• | â­â­â­ å¤æ‚ |
| å¯åŠ¨é€Ÿåº¦ | å¿«ï¼ˆé•œåƒæ‹‰å–åï¼‰ | æ…¢ï¼ˆé¦–æ¬¡å®‰è£…ï¼‰ |
| ç¯å¢ƒéš”ç¦» | âœ… å®Œå…¨éš”ç¦» | âŒ å¯èƒ½å†²çª |
| æ€§èƒ½ | ~99%ï¼ˆå‡ ä¹æ— æŸï¼‰ | 100% |
| çµæ´»æ€§ | ä¸­ç­‰ | é«˜ |
| è°ƒè¯•ä¾¿åˆ©æ€§ | ä¸­ç­‰ | é«˜ |

**æ¨èç­–ç•¥**ï¼š
- ğŸ³ **å¿«é€ŸéªŒè¯/å¼€å‘**ï¼šä½¿ç”¨Docker
- ğŸ’» **ç”Ÿäº§è®­ç»ƒ/è°ƒä¼˜**ï¼šä½¿ç”¨æœ¬åœ°ç¯å¢ƒ

---

## ğŸ¯ å¸¸è§Dockerå‘½ä»¤

### åŸºç¡€æ“ä½œ
```bash
# æŸ¥çœ‹è¿è¡Œä¸­çš„å®¹å™¨
docker ps

# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨
docker ps -a

# åœæ­¢å®¹å™¨
docker stop <container_id>

# åˆ é™¤å®¹å™¨
docker rm <container_id>

# æŸ¥çœ‹é•œåƒ
docker images

# åˆ é™¤é•œåƒ
docker rmi <image_id>
```

### è¿›å…¥è¿è¡Œä¸­çš„å®¹å™¨
```bash
docker exec -it <container_name> bash
```

### æŸ¥çœ‹å®¹å™¨æ—¥å¿—
```bash
docker logs <container_name>
```

### å¤åˆ¶æ–‡ä»¶
```bash
# ä»å®¹å™¨å¤åˆ¶åˆ°ä¸»æœº
docker cp <container>:/path/in/container /path/on/host

# ä»ä¸»æœºå¤åˆ¶åˆ°å®¹å™¨
docker cp /path/on/host <container>:/path/in/container
```

---

## ğŸ“Š èµ„æºé™åˆ¶

### è®¾ç½®GPUæ•°é‡
```bash
# ä½¿ç”¨ç‰¹å®šGPU
docker run --device=/dev/dri/renderD128 ...  # GPU 0
docker run --device=/dev/dri/renderD129 ...  # GPU 1
```

### è®¾ç½®å†…å­˜é™åˆ¶
```bash
docker run --shm-size=16G --memory=32G ...
```

### è®¾ç½®CPUé™åˆ¶
```bash
docker run --cpus=8 ...
```

---

## ğŸ” æ•…éšœæ’é™¤

### GPUä¸å¯è§

```bash
# æ£€æŸ¥ä¸»æœºGPU
rocm-smi

# æ£€æŸ¥Dockerèƒ½å¦è®¿é—®GPU
docker run -it --rm --device=/dev/kfd --device=/dev/dri rocm/rocm-terminal rocm-smi

# æ£€æŸ¥è®¾å¤‡æƒé™
ls -la /dev/kfd /dev/dri/
```

### å®¹å™¨å†…éªŒè¯GPU

```bash
# è¿›å…¥å®¹å™¨å
rocm-smi
python3 -c "import torch; print(torch.cuda.is_available())"
```

### ç½‘ç»œé—®é¢˜ï¼ˆå¤šèŠ‚ç‚¹ï¼‰

```bash
# ä½¿ç”¨hostç½‘ç»œ
docker run --network=host ...

# æˆ–æ‰‹åŠ¨æ˜ å°„ç«¯å£
docker run -p 29500:29500 ...
```

---

## ğŸ“ æœ€ä½³å®è·µ

1. **æ•°æ®æŒä¹…åŒ–**ï¼šä½¿ç”¨volumeæŒ‚è½½
   ```bash
   -v $(pwd)/data:/data \
   -v $(pwd)/models:/models \
   -v $(pwd)/output:/output
   ```

2. **å…±äº«å†…å­˜**ï¼šè®¾ç½®è¶³å¤Ÿçš„shm-size
   ```bash
   --shm-size 16G  # å¤šGPUè®­ç»ƒå»ºè®®16G+
   ```

3. **ä»£ç åŒæ­¥**ï¼šæŒ‚è½½æ•´ä¸ªé¡¹ç›®ç›®å½•
   ```bash
   -v $(pwd):/workspace -w /workspace
   ```

4. **ç¯å¢ƒå˜é‡**ï¼šä¼ é€’å¿…è¦çš„é…ç½®
   ```bash
   -e HSA_OVERRIDE_GFX_VERSION=11.0.0 \
   -e NCCL_DEBUG=INFO
   ```

---

## ğŸ“ å‚è€ƒèµ„æº

- [ROCm Docker Hub](https://hub.docker.com/r/rocm/pytorch)
- [ROCm Dockeræ–‡æ¡£](https://rocm.docs.amd.com/en/latest/deploy/docker.html)
- [PyTorch DockeræŒ‡å—](https://pytorch.org/get-started/locally/)
