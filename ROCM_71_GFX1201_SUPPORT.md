# ROCm 7.1 å¯¹ gfx1201 çš„æ”¯æŒæƒ…å†µ

æ ¹æ® [AMD ROCm å®˜æ–¹å…¼å®¹æ€§æ–‡æ¡£](https://rocm.docs.amd.com/en/latest/compatibility/compatibility-matrix.html#rdna-os-700)ï¼š

**ROCm 7.0.x å’Œ 7.1.0 å·²ç»æ­£å¼æ”¯æŒ gfx1201 (AMD Radeon PRO AI PRO R9700)ï¼**

## ğŸ“‹ æ”¯æŒè¯¦æƒ…

### ROCm ç‰ˆæœ¬
- âœ… **ROCm 7.1.0** - æ”¯æŒ gfx1201
- âœ… **ROCm 7.0.2** - æ”¯æŒ gfx1201

### PyTorch ç‰ˆæœ¬
- ROCm 7.1.0: **PyTorch 2.8, 2.7, 2.6**
- ROCm 7.0.2: **PyTorch 2.8, 2.7, 2.6**

### æ”¯æŒçš„æ“ä½œç³»ç»Ÿï¼ˆé‡è¦ï¼ï¼‰

**å¯¹äº gfx1201ï¼Œä»…æ”¯æŒä»¥ä¸‹æ“ä½œç³»ç»Ÿ**ï¼š
- Ubuntu 24.04.3
- Ubuntu 22.04.5
- RHEL 10.0
- RHEL 9.6

æ³¨æ„ï¼šgfx1201 **ä¸æ”¯æŒ** RHEL 9.4, RHEL 8.10, SLES ç­‰å…¶ä»–æ“ä½œç³»ç»Ÿã€‚

## ğŸ” ä¸ºä»€ä¹ˆä½ çš„ç¯å¢ƒè¿˜ä¸å·¥ä½œï¼Ÿ

ä½ å½“å‰ä½¿ç”¨çš„é•œåƒï¼š
```
rocm/pytorch:rocm7.1_ubuntu22.04_py3.10_pytorch_release_2.8.0
```

**å¯èƒ½çš„é—®é¢˜**ï¼š

1. **PyTorch ç¼–è¯‘ç›®æ ‡**
   - è™½ç„¶ ROCm 7.1 æ”¯æŒ gfx1201
   - ä½† PyTorch é•œåƒå¯èƒ½æ²¡æœ‰ä¸º gfx1201 ç¼–è¯‘
   - éœ€è¦ç¡®è®¤ PyTorch æ˜¯å¦åŒ…å« gfx1201 çš„ä»£ç å¯¹è±¡

2. **Ubuntu ç‰ˆæœ¬**
   - ä½ çš„é•œåƒæ˜¯ Ubuntu 22.04
   - éœ€è¦ç¡®è®¤æ˜¯å¦æ˜¯ 22.04.5 ç‰ˆæœ¬

## âœ… è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: éªŒè¯å½“å‰é•œåƒæ˜¯å¦åŒ…å« gfx1201 æ”¯æŒ

åœ¨ Docker å®¹å™¨ä¸­è¿è¡Œï¼š

```bash
# æ£€æŸ¥ PyTorch æ”¯æŒçš„æ¶æ„
python3 -c "import torch; print(torch.cuda.get_arch_list())"

# æ£€æŸ¥ HIP/ROCm åº“
ls -la /opt/rocm/lib/ | grep gfx12

# æ£€æŸ¥ Ubuntu ç‰ˆæœ¬
cat /etc/os-release | grep VERSION
```

å¦‚æœè¾“å‡ºä¸­åŒ…å« `gfx1201` æˆ– `gfx12`ï¼Œè¯´æ˜é•œåƒå·²æ”¯æŒã€‚

### æ–¹æ¡ˆ 2: ä½¿ç”¨æœ€æ–°çš„ ROCm 7.1 é•œåƒ

```bash
# æ‹‰å–æœ€æ–°é•œåƒ
docker pull rocm/pytorch:rocm7.1_ubuntu22.04_py3.10_pytorch_release_2.8.0

# æˆ–è€…å°è¯• latest æ ‡ç­¾
docker pull rocm/pytorch:latest
```

### æ–¹æ¡ˆ 3: ä½¿ç”¨ Ubuntu 24.04 çš„é•œåƒ

æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œgfx1201 åœ¨ Ubuntu 24.04.3 ä¸Šæœ‰æ›´å¥½çš„æ”¯æŒï¼š

```bash
# æ£€æŸ¥æ˜¯å¦æœ‰ Ubuntu 24.04 çš„é•œåƒ
docker search rocm/pytorch | grep 24.04

# å¦‚æœæœ‰ï¼Œæ‹‰å–
docker pull rocm/pytorch:rocm7.1_ubuntu24.04_py3.10_pytorch_release_2.8.0
```

### æ–¹æ¡ˆ 4: è‡ªå·±ç¼–è¯‘ PyTorch for gfx1201

å¦‚æœå®˜æ–¹é•œåƒç¡®å®ä¸åŒ…å« gfx1201 æ”¯æŒï¼š

```bash
# åœ¨å®¹å™¨å†…
git clone https://github.com/pytorch/pytorch.git
cd pytorch

# è®¾ç½®ç¼–è¯‘ç›®æ ‡
export PYTORCH_ROCM_ARCH=gfx1201

# ç¼–è¯‘ï¼ˆéœ€è¦å‡ å°æ—¶ï¼‰
python3 tools/amd_build/build_amd.py
python3 setup.py install
```

## ğŸ¯ æ¨èçš„æµ‹è¯•æ­¥éª¤

### æ­¥éª¤ 1: æ£€æŸ¥é•œåƒæ”¯æŒ

```bash
# åœ¨ Docker å®¹å™¨å†…
cd /workspace

# åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > check_gfx1201.py << 'EOF'
import torch
import sys

print("PyTorch ç‰ˆæœ¬:", torch.__version__)
print("ROCm ç‰ˆæœ¬:", torch.version.hip if hasattr(torch.version, 'hip') else 'N/A')

# æ£€æŸ¥æ”¯æŒçš„æ¶æ„
try:
    archs = torch.cuda.get_arch_list()
    print("\næ”¯æŒçš„æ¶æ„åˆ—è¡¨:")
    for arch in archs:
        print(f"  - {arch}")
    
    if 'gfx1201' in str(archs) or 'gfx12' in str(archs):
        print("\nâœ“ é•œåƒæ”¯æŒ gfx1201!")
    else:
        print("\nâœ— é•œåƒä¸æ”¯æŒ gfx1201")
        print("   éœ€è¦ä½¿ç”¨å…¼å®¹æ¨¡å¼ (gfx1101)")
except Exception as e:
    print(f"é”™è¯¯: {e}")

# æ£€æŸ¥ GPU
print(f"\nGPU å¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU åç§°: {torch.cuda.get_device_name(0)}")
EOF

python3 check_gfx1201.py
```

### æ­¥éª¤ 2: æ ¹æ®ç»“æœé€‰æ‹©ç­–ç•¥

#### å¦‚æœé•œåƒæ”¯æŒ gfx1201

```bash
# ä½¿ç”¨åŸç”Ÿé…ç½®
export HSA_OVERRIDE_GFX_VERSION=12.0.1
export PYTORCH_ROCM_ARCH=gfx1201
export AMD_SERIALIZE_KERNEL=1
export GPU_MAX_HW_QUEUES=4
```

#### å¦‚æœé•œåƒä¸æ”¯æŒ gfx1201

```bash
# ä½¿ç”¨å…¼å®¹æ¨¡å¼ï¼ˆä½ å½“å‰çš„é…ç½®ï¼‰
export HSA_OVERRIDE_GFX_VERSION=11.0.1
export PYTORCH_ROCM_ARCH=gfx1101
export AMD_SERIALIZE_KERNEL=3
export GPU_MAX_HW_QUEUES=1
```

## ğŸ“ æ›´æ–° docker_run.sh çš„å»ºè®®

å¦‚æœéªŒè¯åå‘ç°é•œåƒæ”¯æŒ gfx1201ï¼Œå¯ä»¥æ›´æ–°é…ç½®ï¼š

```bash
# ç¼–è¾‘ docker_run.shï¼Œä¿®æ”¹ç¯å¢ƒå˜é‡ä¸ºï¼š
  -e HSA_OVERRIDE_GFX_VERSION=12.0.1 \
  -e PYTORCH_ROCM_ARCH=gfx1201 \
  -e AMD_SERIALIZE_KERNEL=1 \
  -e GPU_MAX_HW_QUEUES=2 \
  -e HSA_ENABLE_SDMA=0 \
  -e PYTORCH_HIP_ALLOC_CONF=max_split_size_mb:256 \
```

## ğŸ”§ è¯Šæ–­å‘½ä»¤åˆé›†

```bash
# åœ¨ Docker å®¹å™¨å†…è¿è¡Œ

# 1. æ£€æŸ¥ Ubuntu ç‰ˆæœ¬
cat /etc/os-release

# 2. æ£€æŸ¥ ROCm ç‰ˆæœ¬
cat /opt/rocm/.info/version

# 3. æ£€æŸ¥ PyTorch ç¼–è¯‘ä¿¡æ¯
python3 -c "import torch; print(torch.__config__.show())"

# 4. æ£€æŸ¥ HIP åº“ä¸­çš„ gfx æ”¯æŒ
find /opt/rocm -name "*gfx12*" 2>/dev/null | head -10

# 5. æ£€æŸ¥å®é™… GPU
rocminfo | grep -i "name.*gfx"
```

## ğŸ¯ æœ€ç»ˆå»ºè®®

### ç«‹å³è¡ŒåŠ¨
1. **å…ˆéªŒè¯**å½“å‰é•œåƒæ˜¯å¦å·²åŒ…å« gfx1201 æ”¯æŒ
2. **å¦‚æœæ”¯æŒ**ï¼Œæ›´æ–°ä¸ºåŸç”Ÿ gfx1201 é…ç½®
3. **å¦‚æœä¸æ”¯æŒ**ï¼Œç»§ç»­ä½¿ç”¨ gfx1101 å…¼å®¹æ¨¡å¼

### é•¿æœŸæ–¹æ¡ˆ
ç­‰å¾… AMD/PyTorch å‘å¸ƒåŒ…å« gfx1201 ç¼–è¯‘ç›®æ ‡çš„æ›´æ–°é•œåƒï¼Œæˆ–è€…è€ƒè™‘ä»æºç ç¼–è¯‘ã€‚

## ğŸ“š å‚è€ƒ

- [AMD ROCm å…¼å®¹æ€§çŸ©é˜µ](https://rocm.docs.amd.com/en/latest/compatibility/compatibility-matrix.html#rdna-os-700)
- [ROCm æ”¯æŒçš„ GPU](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus)
- [PyTorch ROCm æ–‡æ¡£](https://pytorch.org/docs/stable/notes/hip.html)
